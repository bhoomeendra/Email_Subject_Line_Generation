{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f226cc6-32c4-4961-a770-b5875312463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List,Dict,Literal\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9081ef-7a96-4368-b6f3-3c8a61366cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigDataSet(BaseModel):\n",
    "        split: Literal['train','dev','test']\n",
    "        model_name: Literal['gpt2-large','gpt2-medium','gpt2','gpt2-xl'] = 'gpt2'\n",
    "        trun_limit: int = 500    \n",
    "        BASEPATH : Path = Path(\"../data/\")\n",
    "        debug: bool = True\n",
    "\n",
    "class EnronEmailDataset(Dataset):\n",
    "    # Read About MRO(Method Resolution Order)    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: ConfigDataSet\n",
    "    ):\n",
    "        # As Config is at as just data we can us it with pydatic\n",
    "        self.config = config\n",
    "        self.tokenizer  = GPT2Tokenizer.from_pretrained(self.config.model_name)\n",
    "        # Setting pad tokenizer as end of sent token\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        # self.file_paths: List[str] = [ self.config.BASEPATH/self.config.split/name \n",
    "        #                               for name in \n",
    "        #                               os.listdir(self.config.BASEPATH/self.config.split)]\n",
    "        # self.emails: List[str] = [ open(self.file_paths[idx],'r').read().strip()\\\n",
    "        #                             for idx in tqdm(range(len(self.file_paths)),\n",
    "        #                                             desc=\"Loading Email\") ]\n",
    "        data = pd.read_csv(f\"../data/{self.config.split}.csv\")\n",
    "        self.email = data['body'].tolist()\n",
    "        self.subject = data['subject'].tolist()\n",
    "        if self.config.split != 'train':\n",
    "            self.ann0 = data['ann0'].tolist()\n",
    "            self.ann1 = data['ann1'].tolist()\n",
    "            self.ann2 = data['ann2'].tolist()\n",
    "            \n",
    "        # if self.config.debug:\n",
    "        #     print(f\"Possible Max lenght for the model is\\\n",
    "        #             {self.tokenizer.model_max_length}\")\n",
    "        #     print(f\"First Data point of {self.config.split} tokenized as :\\n\",self[0])\n",
    "        #     for idx in tqdm(range(len(self)),desc=\"Length Test:\"):\n",
    "        #         if len(self[idx]['input_ids'])>=self.tokenizer.model_max_length:\n",
    "        #             raise(f\"ERROR: The length of {idx} data point \\\n",
    "        #             in {self.split} split is more the {self.tokenizer.model_max_length}\")\n",
    "        #     print(\"Passed all CHECKS\")\n",
    "        \n",
    "    def clean_text(\n",
    "        self,\n",
    "        text:str\n",
    "        ):\n",
    "        # Updated so that it comes from config\n",
    "        # ipdb.set_trace()\n",
    "        text = re.sub(' +',' ',text)\n",
    "        text = re.sub('\\n+','\\n',text)\n",
    "        # If it is non-numeric char also char like /.- are not removed\n",
    "        text = re.sub('[^A-Za-z0-9\\n\\s\\\\/.-]+','',text)\n",
    "        return text\n",
    "        \n",
    "        \n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx:int\n",
    "    ):\n",
    "        \n",
    "        \"\"\" \n",
    "        returns the input_ids and attention_maks also tuncates if\n",
    "        the email is longer that what is specified in config\n",
    "        \"\"\"\n",
    "        \n",
    "        # with open(self.file_paths[idx],'r') as f:\n",
    "        #     email_with_subject = f.read().strip()\n",
    "        \n",
    "\n",
    "        email,subject = self.email[idx],self.subject[idx]\n",
    "        \n",
    "        email = self.clean_text(email)\n",
    "\n",
    "        # email = ''.join(email.split()[:self.config.trun_limit])\n",
    "        tok_email = self.tokenizer(email,truncation=True,max_length=self.config.trun_limit)\n",
    "        tok_subject = self.tokenizer( \"\\n\\n@subject\\n\"+ subject + \"\\n[ENDOFEMAIL]\\n\"+\" <|endoftext|>\",\n",
    "                                     truncation=True,max_length=self.config.trun_limit)\n",
    "        \n",
    "        tok_email['input_ids'].extend(tok_subject['input_ids'])\n",
    "        tok_email['attention_mask'].extend(tok_subject['attention_mask'])\n",
    "\n",
    "        return tok_email\n",
    "\n",
    "\n",
    "        # \n",
    "        # tok_subject = self.tokenizer( \"@subject\\n\"+ subject + \" <|endoftext|>\",\n",
    "        #                              truncation=True,max_length=self.config.trun_limit)\n",
    "        \n",
    "        # Token from which CLM will start Finetuning\n",
    "        # st_gen_token = len(tok_email['input_ids'])\n",
    "        \n",
    "        # tok_email['input_ids'].extend(tok_subject['input_ids'])\n",
    "        # tok_email['attention_mask'].extend([0]*len(tok_subject['attention_mask']))\n",
    "        \n",
    "        \n",
    "         # return ({'input_ids':torch.tensor(tok_email['input_ids']),\n",
    "         #         \"attention_mask\":torch.tensor(tok_email['attention_mask'])},st_gen_token)\n",
    "\n",
    "        \n",
    "    def __len__(\n",
    "        self\n",
    "    ):\n",
    "        return len(self.email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2639ff1e-001f-4215-af2c-bddac3567228",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataconfig = ConfigDataSet( split='train',\n",
    "                            trun_limit=300)\n",
    "train_dataset = EnronEmailDataset(train_dataconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e7407b-1551-4829-848e-fe8656b7b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataconfig = ConfigDataSet( split='dev',\n",
    "                            trun_limit=300)\n",
    "val_dataset = EnronEmailDataset(val_dataconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d78826-645b-49bd-acd2-618d5ffc6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=train_dataset.tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9013721-70cf-45e7-b3db-41ff47cdc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_collator([train_dataset[0],train_dataset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cdfd584-9277-43c7-ab00-6f12b64fe7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3006dd4-42cc-4377-af3e-5eb1ecc71563",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  464,  1321, 18307,   416,   262,  1708,   304,    12,  4529,   318,\n",
       "          5292,   691,   329,   262,   751,   411,  3826,   290,   743,  3994,\n",
       "         15279,   290,    14,   273, 21929,  2587,    13,   198,  7149, 28759,\n",
       "          2423,  1005, 26084,  3411, 44832,   393,   584,   779,   286,   393,\n",
       "          2263,   286,   597,  2223,  2402,   428,  1321,   416,  6506,   393,\n",
       "         12066,   584,   621,   262,  5292, 17800,   318, 12244,   416,  1099,\n",
       "           290,   743,  2426,   606,   284,  4301,   393,  3026, 12247,    13,\n",
       "           198,  1532,   345,  2722,   428,  6946,   287,  4049,  3387,  2800,\n",
       "           514,  3393,   379, 22131,   767,  5332,    12,    24,  3064,   290,\n",
       "         12233,   262,  6946,   422,   597,  3644,   393,  3127,  1080,    13,\n",
       "           198,  7003,   428,  3053,   290,   597, 32161,   389,  4762,   284,\n",
       "           307,  1479,   286,   597,  9471,   393,   584, 11855,   326,  1244,\n",
       "         22533,  2689,   597,  3644,  1080,   656,   543,   340,   318,  2722,\n",
       "           290,  4721,   340,   318,   262,  5798,   286,   262, 17800,   284,\n",
       "          4155,   326,   340,   318,  9471,  1479,   290,   645,  5798,   318,\n",
       "          6292,   416,   262, 29788,   329,   597,  2994,   393,  2465, 21539,\n",
       "           287,   597,   835,   287,   262,  1785,   326,   884,   257,  9471,\n",
       "           393, 11855,  2152,    13,   198,   198,    31, 32796,   198, 12310,\n",
       "          8322, 18261,   284, 19694,    12, 18227,    36,    12,    16, 16652,\n",
       "           352,   286,   362,   198,    58, 10619, 19238, 27630,  4146,    60,\n",
       "           198,   220, 50256],\n",
       "        [ 7371,   314,   303,  6209,   655,  2077,   262, 13532,  5475,   326,\n",
       "           547,  7530,   329,   262,   362,   358,   290,  3888,   606,   866,\n",
       "            13,   198,   464,   691,   649,  1517,   318,  1633, 29498,  2058,\n",
       "           736,   656,   711,   319,  3635,   257,  6228,   718,   285,    86,\n",
       "            13,   198,   265,   262,  3095,    66,    13,   198, 26408,   468,\n",
       "           587, 22000,   262,  2386,   361,  3317,  3404,  4445,   290,  3863,\n",
       "          3867,   517,  3095,    66,   284, 22843,   393, 14552, 25470,   284,\n",
       "          3368,   523,   881,  1016,   284,  2386,    72,   287,  1339,   286,\n",
       "         28014,    13,   198,  1532,   345,   423,   597,  2683,   393,   611,\n",
       "          1243,   651,  7165,  3387, 17666, 22898,   284,   869,   502,   314,\n",
       "           460,  1282,   287,   611,  2622,    13,   198, 48059,  5821,  1410,\n",
       "           319,  4379,   345,   319,   262,   767,   400,    13,   198,   198,\n",
       "            31, 32796,   198,    44,  2389,  8220,    12,  8220,    33,    12,\n",
       "         27857,    51,   198,    58, 10619, 19238, 27630,  4146,    60,   198,\n",
       "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[  464,  1321, 18307,   416,   262,  1708,   304,    12,  4529,   318,\n",
       "          5292,   691,   329,   262,   751,   411,  3826,   290,   743,  3994,\n",
       "         15279,   290,    14,   273, 21929,  2587,    13,   198,  7149, 28759,\n",
       "          2423,  1005, 26084,  3411, 44832,   393,   584,   779,   286,   393,\n",
       "          2263,   286,   597,  2223,  2402,   428,  1321,   416,  6506,   393,\n",
       "         12066,   584,   621,   262,  5292, 17800,   318, 12244,   416,  1099,\n",
       "           290,   743,  2426,   606,   284,  4301,   393,  3026, 12247,    13,\n",
       "           198,  1532,   345,  2722,   428,  6946,   287,  4049,  3387,  2800,\n",
       "           514,  3393,   379, 22131,   767,  5332,    12,    24,  3064,   290,\n",
       "         12233,   262,  6946,   422,   597,  3644,   393,  3127,  1080,    13,\n",
       "           198,  7003,   428,  3053,   290,   597, 32161,   389,  4762,   284,\n",
       "           307,  1479,   286,   597,  9471,   393,   584, 11855,   326,  1244,\n",
       "         22533,  2689,   597,  3644,  1080,   656,   543,   340,   318,  2722,\n",
       "           290,  4721,   340,   318,   262,  5798,   286,   262, 17800,   284,\n",
       "          4155,   326,   340,   318,  9471,  1479,   290,   645,  5798,   318,\n",
       "          6292,   416,   262, 29788,   329,   597,  2994,   393,  2465, 21539,\n",
       "           287,   597,   835,   287,   262,  1785,   326,   884,   257,  9471,\n",
       "           393, 11855,  2152,    13,   198,   198,    31, 32796,   198, 12310,\n",
       "          8322, 18261,   284, 19694,    12, 18227,    36,    12,    16, 16652,\n",
       "           352,   286,   362,   198,    58, 10619, 19238, 27630,  4146,    60,\n",
       "           198,   220,  -100],\n",
       "        [ 7371,   314,   303,  6209,   655,  2077,   262, 13532,  5475,   326,\n",
       "           547,  7530,   329,   262,   362,   358,   290,  3888,   606,   866,\n",
       "            13,   198,   464,   691,   649,  1517,   318,  1633, 29498,  2058,\n",
       "           736,   656,   711,   319,  3635,   257,  6228,   718,   285,    86,\n",
       "            13,   198,   265,   262,  3095,    66,    13,   198, 26408,   468,\n",
       "           587, 22000,   262,  2386,   361,  3317,  3404,  4445,   290,  3863,\n",
       "          3867,   517,  3095,    66,   284, 22843,   393, 14552, 25470,   284,\n",
       "          3368,   523,   881,  1016,   284,  2386,    72,   287,  1339,   286,\n",
       "         28014,    13,   198,  1532,   345,   423,   597,  2683,   393,   611,\n",
       "          1243,   651,  7165,  3387, 17666, 22898,   284,   869,   502,   314,\n",
       "           460,  1282,   287,   611,  2622,    13,   198, 48059,  5821,  1410,\n",
       "           319,  4379,   345,   319,   262,   767,   400,    13,   198,   198,\n",
       "            31, 32796,   198,    44,  2389,  8220,    12,  8220,    33,    12,\n",
       "         27857,    51,   198,    58, 10619, 19238, 27630,  4146,    60,   198,\n",
       "           220,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341f729e-558a-46c0-b137-6a42f93a6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../model_weights/GPT2_FT_Model\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=out_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4, # try with 2\n",
    "    per_device_eval_batch_size=4,  #  try with 2\n",
    "    num_train_epochs=20,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    load_best_model_at_end=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8285e99f-b36a-4e56-b9ee-764056a97c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = GPT2LMHeadModel.from_pretrained(train_dataconfig.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2de33a-091c-4306-9f6c-fcb5cefc4e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sisodiya.bhoomendra/venvs/python3.9_global/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbss\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/sisodiya.bhoomendra/github/Email-Subject-Line-Generation/notebooks/wandb/run-20231108_131537-o0k6urvl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bss/huggingface/runs/o0k6urvl' target=\"_blank\">valiant-forest-10</a></strong> to <a href='https://wandb.ai/bss/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bss/huggingface' target=\"_blank\">https://wandb.ai/bss/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bss/huggingface/runs/o0k6urvl' target=\"_blank\">https://wandb.ai/bss/huggingface/runs/o0k6urvl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72180' max='72180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72180/72180 4:05:26, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.112700</td>\n",
       "      <td>3.070092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.832300</td>\n",
       "      <td>3.011306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.626500</td>\n",
       "      <td>3.036852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.528500</td>\n",
       "      <td>3.025615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.341300</td>\n",
       "      <td>3.049123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.254000</td>\n",
       "      <td>3.092557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.133000</td>\n",
       "      <td>3.089626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.042500</td>\n",
       "      <td>3.175704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.980100</td>\n",
       "      <td>3.187019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.901600</td>\n",
       "      <td>3.252630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.853700</td>\n",
       "      <td>3.284768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.749300</td>\n",
       "      <td>3.335743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.701500</td>\n",
       "      <td>3.392719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.659400</td>\n",
       "      <td>3.370989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.614500</td>\n",
       "      <td>3.435112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.569200</td>\n",
       "      <td>3.453485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.539400</td>\n",
       "      <td>3.470948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.510800</td>\n",
       "      <td>3.496083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.494300</td>\n",
       "      <td>3.520426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.489700</td>\n",
       "      <td>3.524045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=72180, training_loss=1.9949246016259536, metrics={'train_runtime': 14732.7529, 'train_samples_per_second': 19.597, 'train_steps_per_second': 4.899, 'total_flos': 3.5340600609792e+16, 'train_loss': 1.9949246016259536, 'epoch': 20.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer = Trainer(\n",
    "    model=gpt2,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "456831f7-1d34-4ed8-9fa6-6b19aac9aab0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model_weights\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(model_output_path)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(model_output_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "model_output_path = '../model_weights'\n",
    "trainer.save_model(model_output_path)\n",
    "train_dataset.tokenizer.save_pretrained(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839a8c0f-7ac7-4e7a-9723-bfe3e0ec2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = GPT2LMHeadModel.from_pretrained(\"../model_weights/GPT2_FT_Model/checkpoint-7218\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27e09c07-abff-480f-a109-72f42dabb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mail = train_dataset.clean_text(\"\"\"\"I just got off the phone with Darren Vanek.\n",
    "We have been talking  about what is needed for about a month now.\n",
    "Almost two weeks ago he said  he wanted a contract that allowed him to call for a letter of credit if one were  needed in the future and that would suffice.\n",
    "Apparently, a paralegal, is involved in generating such a contract and she  was out all of last week.\n",
    "Darren said that he has no control over when the  contract actually gets sent to me.\n",
    "Please do what you can to expedite the  emailing of that contract to me so that I can order gas beyond Dec. 2001.\n",
    "Thanks and regards,\"\"\") + \"\\n\\n@subject\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e5311ea-db6b-4ce4-b955-768279d1df50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just got off the phone with Darren Vanek.\\nWe have been talking about what is needed for about a month now.\\nAlmost two weeks ago he said he wanted a contract that allowed him to call for a letter of credit if one were needed in the future and that would suffice.\\nApparently a paralegal is involved in generating such a contract and she was out all of last week.\\nDarren said that he has no control over when the contract actually gets sent to me.\\nPlease do what you can to expedite the emailing of that contract to me so that I can order gas beyond Dec. 2001.\\nThanks and regards \\n\\n@subject\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c9ec6e0-3e30-40c5-8cab-a3437ec75c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = train_dataset.tokenizer(mail, return_tensors='pt').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6d1a2ad-a933-4cd7-8c8b-1fbe3a591ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# context = tokenizer('I want to fly a', return_tensors='pt')\n",
    "\n",
    "prediction = gpt2.generate(**out,max_new_tokens= 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9ec760f-3af4-4d4d-8a5c-53c2610b20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = train_dataset.tokenizer.decode(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d4ead05-bde3-42b0-b872-f0e9a8bf7d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just got off the phone with Darren Vanek.\\nWe have been talking about what is needed for about a month now.\\nAlmost two weeks ago he said he wanted a contract that allowed him to call for a letter of credit if one were needed in the future and that would suffice.\\nApparently a paralegal is involved in generating such a contract and she was out all of last week.\\nDarren said that he has no control over when the contract actually gets sent to me.\\nPlease do what you can to expedite the emailing of that contract to me so that I can order gas beyond Dec. 2001.\\nThanks and regards \\n\\n@subject\\nGas Contract\\n[ENDOFEMAIL]\\n                                                                                          '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a762e323-6e5c-40ea-b42f-0329cc93f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = output.split(\"@subject\\n\")[-1].split(\"\\n[ENDOFEMAIL]\\n\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34281c-8151-45b5-b975-acc7c9a3373d",
   "metadata": {},
   "source": [
    "## Testing on Dev and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39b1167-b9ae-44fc-b291-cb5a57547dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv(\"../data/dev.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b43178-650e-46af-8c29-01f09e57c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodys = dev['body'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b210e-cf45-4969-92c5-bc8a18cfc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf0ad54-b702-4528-a9b3-3ac3eaaaa597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailSubjectGen(emails):\n",
    "    subjects = []\n",
    "    for email in tqdm(emails,desc=\"Generated:\"):\n",
    "        tok = train_dataset.tokenizer(train_dataset.clean_text(email)+\"\\n\\n@subject\\n\"\\\n",
    "                                      , return_tensors='pt',\n",
    "                                      max_length=train_dataset.config.trun_limit,\n",
    "                                      truncation=True\n",
    "                                     ).to('cuda')\n",
    "        prediction = gpt2.generate(**tok,max_new_tokens=100,\n",
    "                                   pad_token_id=train_dataset.tokenizer.eos_token_id)\n",
    "        output = train_dataset.tokenizer.decode(prediction[0])\n",
    "        x = output.split(\"@subject\\n\")[-1].split(\"\\n[ENDOFEMAIL]\\n\")[0]\n",
    "        subjects.append(x)\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d91a8c66-9e32-4948-9099-4aa001ee1025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated:: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1960/1960 [33:02<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_gen_sub = emailSubjectGen(dev['body'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "355258ef-ff02-4087-bb1f-993785dd54cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated:: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1906/1906 [32:08<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "test_gen_sub = emailSubjectGen(test['body'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bba5560-4194-418c-8c7a-383996d74ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev['gen_subject'] = dev_gen_sub\n",
    "test['gen_subject']= test_gen_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f07b89a-0061-4682-847b-630d80eeb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.to_csv(\"../data/output/output_dev.csv\")\n",
    "test.to_csv(\"../data/output/output_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "465bddc6-4d2a-40e3-a579-6c7b51f246ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL'], use_stemmer=True)\n",
    "def rouge_cal(data,an1,an2):\n",
    "    r1,r2,rl = 0,0,0\n",
    "    counter = 0\n",
    "    for a0,a1 in zip(data[an1].tolist(),data[an2].tolist()):\n",
    "        scores = scorer.score(a0,a1)\n",
    "        # print(scores)\n",
    "        r1 += scores['rouge1'].fmeasure\n",
    "        r2 += scores['rouge2'].fmeasure\n",
    "        rl += scores['rougeL'].fmeasure\n",
    "        counter+=1\n",
    "    print(f\"Between {an1} and {an2} the scores are :\\n \\\n",
    "    Rouge-1 {r1/counter} Rouge-2 {r2/counter} Rouge-L {rl/counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "081d46c3-c883-44e0-b402-98d91a9fb08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and subject the scores are :\n",
      "     Rouge-1 0.2732518349073312 Rouge-2 0.11974588874868865 Rouge-L 0.2668310967098438\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(dev,'gen_subject','subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0aeb8dc-210c-4aea-9a04-63632425315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and subject the scores are :\n",
      "     Rouge-1 0.2594523875188608 Rouge-2 0.11903202393279694 Rouge-L 0.2541247011201646\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(test,'gen_subject','subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cc7f8ea-ba07-44da-a024-474173ed760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and ann0 the scores are :\n",
      "     Rouge-1 0.28433004494761366 Rouge-2 0.13417300498284032 Rouge-L 0.27501508418350806\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(dev,'gen_subject','ann0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "228745d7-18c3-4915-8ffa-bcbafafa53e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and ann1 the scores are :\n",
      "     Rouge-1 0.27471732736901805 Rouge-2 0.1363361165898205 Rouge-L 0.2660431652985551\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(dev,'gen_subject','ann1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a615e260-cd53-487b-acd0-215e124dc1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and ann2 the scores are :\n",
      "     Rouge-1 0.28043781097455694 Rouge-2 0.1309949964477969 Rouge-L 0.26979476279555104\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(dev,'gen_subject','ann2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75655fc3-4afb-4e4a-aa2d-05a1805e5b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and ann0 the scores are :\n",
      "     Rouge-1 0.29036829341388176 Rouge-2 0.14427877439013237 Rouge-L 0.2808761198145867\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(test,'gen_subject','ann0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e17b1ce8-8641-4abb-b8aa-a23088fc06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and ann1 the scores are :\n",
      "     Rouge-1 0.28732260159837997 Rouge-2 0.1381158409512439 Rouge-L 0.2779335316707248\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(test,'gen_subject','ann1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fab455d6-cfc1-4134-bdbd-ffde22a55476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between gen_subject and ann2 the scores are :\n",
      "     Rouge-1 0.29493567042928837 Rouge-2 0.14614512483560554 Rouge-L 0.2846064299225586\n"
     ]
    }
   ],
   "source": [
    "rouge_cal(test,'gen_subject','ann2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f8db3-53d8-479b-84ad-195496a48ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
